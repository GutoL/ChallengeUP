{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_Official_Model (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpRZrFLrFaf7",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Imports & Set Path\n",
        "import pandas as pd\n",
        "from random import randint\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense, CuDNNLSTM, LSTM\n",
        "from keras.layers import Add, Average \n",
        "from keras.layers import Dropout, Activation, Input, Flatten\n",
        "from keras.layers import TimeDistributed, Bidirectional\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "path = 'Data/' #add the path of your data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDsWzSrhFJ9X",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title reading from drive (if you are using google collaboratory)\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "path = 'gdrive/My Drive/challenge-up/'\n",
        "\n",
        "base = pd.read_csv(path + 'CompleteDataSet_training_competition.csv')\n",
        "base.loc[base.Tag==20,'Tag'] = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA2SYHrvFvsI",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Split per second\n",
        "def split_per_second(dataFrames=None,sensors=None,getLables=True):\n",
        "\n",
        "  higher_length_sample = 0   \n",
        "  \n",
        "  dataFrames_splited_per_second = []\n",
        "\n",
        "  labels_splited_per_second = np.zeros((1,12))\n",
        "\n",
        "  cont=0\n",
        "  current_index=0\n",
        "  \n",
        "  dataFrame = dataFrames\n",
        "  \n",
        "  teste = dataFrame['TimeStamps'].apply(\n",
        "      lambda x: x.replace(microsecond=0))\n",
        "  \n",
        "  teste = teste.drop_duplicates()\n",
        "  \n",
        "  for y in range(len(teste)):\n",
        "    tDataFrame = dataFrame.iloc[current_index:(current_index+25),:] \n",
        "    \n",
        "    tempDataFrame = tDataFrame.loc[\n",
        "        tDataFrame['TimeStamps']\n",
        "        .apply(lambda x: x.replace(microsecond=0))\n",
        "        .isin(teste.iloc[[y]])\n",
        "    ]\n",
        "    \n",
        "    \n",
        "    if(tempDataFrame.shape[0] == 0):\n",
        "      print(\"ZERO:\")\n",
        "      print(y,teste[y])\n",
        "      print(tempDataFrame.head())\n",
        "      continue\n",
        "        \n",
        "    \n",
        "    if higher_length_sample < len(tempDataFrame):\n",
        "      higher_length_sample = len(tempDataFrame)\n",
        "      \n",
        "    current_index+=len(tempDataFrame)\n",
        "    \n",
        "    if getLables == True:\n",
        "      label_mode = tempDataFrame['Tag'].mode()\n",
        "\n",
        "\n",
        "      if label_mode.shape[0] > 1:\n",
        "        size=(len(tempDataFrame['Tag'])//2)\n",
        "        df_new1 = tempDataFrame[:size]\n",
        "        df_new2 = tempDataFrame[size:]\n",
        "        \n",
        "        df_new1 = np.asarray(df_new1.iloc[:,sensors])\n",
        "        dataFrames_splited_per_second.append(df_new1)\n",
        "        df_new2 = np.asarray(df_new2.iloc[:,sensors])\n",
        "        dataFrames_splited_per_second.append(df_new2)\n",
        "        \n",
        "        cont+=1\n",
        "        \n",
        "                \n",
        "      else:\n",
        "        tempDataFrame = np.asarray(tempDataFrame.iloc[:,sensors])\n",
        "        dataFrames_splited_per_second.append(tempDataFrame)\n",
        "      \n",
        "      \n",
        "      label_mode = np.asarray(label_mode)-1\n",
        "      label_mode = to_categorical(label_mode,num_classes=12)\n",
        "\n",
        "      labels_splited_per_second = np.append(\n",
        "          labels_splited_per_second,label_mode,axis=0)\n",
        "        \n",
        "    else:\n",
        "      tempDataFrame = np.asarray(tempDataFrame.iloc[:,sensors])\n",
        "      dataFrames_splited_per_second.append(tempDataFrame)\n",
        "    \n",
        "    cont+=1\n",
        "      \n",
        "  dataFrames_splited_per_second = np.asarray(dataFrames_splited_per_second)\n",
        "  \n",
        "  if getLables == True:\n",
        "    labels_splited_per_second = np.delete(labels_splited_per_second,0,0)\n",
        "  \n",
        "  if getLables == True:\n",
        "    return dataFrames_splited_per_second,labels_splited_per_second,higher_length_sample\n",
        "  else:\n",
        "    return dataFrames_splited_per_second, higher_length_sample \n",
        "\n",
        "sensors = [\n",
        "    1,2,3, #accelerometer ankle\n",
        "    4,5,6, #gyroscope ankle\n",
        "    #7, #luminosity ankle\n",
        "    \n",
        "    8,9,10, #accelerometer right pocket\n",
        "    11,12,13, #gyroscope right pocket\n",
        "    #14, #luminosity right pocket\n",
        "    \n",
        "    15,16,17, # accelerometer belt\n",
        "    18,19,20, # gyroscope belt\n",
        "    #21, #luminosity belt\n",
        "    \n",
        "    22,23,24, # accelerometer neck\n",
        "    25,26,27, # gyroscope neck\n",
        "    #28, #luminosity neck\n",
        "    \n",
        "    #29,30,31, # accelerometer wrist\n",
        "    #32,33,34, # gyroscope wrist\n",
        "    ##35, #luminosity wrist\n",
        "    \n",
        "    #36 #brain sensor\n",
        "]\n",
        "   \n",
        "\n",
        "base['TimeStamps'] = pd.to_datetime(base['TimeStamps'])\n",
        "train_dataFrames_splited_per_second,Y_train,higher_length_train = split_per_second(base,sensors,True)\n",
        "\n",
        "train_dataFrames_splited_per_second,test_dataFrames_splited_per_second, Y_train, Y_test = train_test_split(train_dataFrames_splited_per_second,Y_train,test_size=0.25,random_state=10)\n",
        "higher_length = higher_length_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCwB54isZZLm",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Pad data\n",
        "\n",
        "def match_data(data=None,index=0,final_len=25):\n",
        "  \n",
        "  if(len(data)>final_len):\n",
        "    print(\"Error!\")\n",
        "    return(-1)\n",
        "  \n",
        "  final_len = final_len-len(data)\n",
        "  \n",
        "  for x in range(final_len):\n",
        "    i = index - x\n",
        "    vector = data[i]\n",
        "    vector = np.reshape(vector,(1,vector.shape[0]))\n",
        "    data = np.concatenate((data[:i],vector,data[i:]),axis=0)\n",
        "\n",
        "  return data\n",
        "\n",
        "def completeData(X=None,final_len=22):\n",
        "  \n",
        "  new_dataFrames_splited_by_second = []\n",
        "  for x in range(len(X)):\n",
        "    test = match_data(\n",
        "        data=X[x],\n",
        "        index=len(X[x])-1,\n",
        "        final_len=higher_length\n",
        "    )\n",
        "    new_dataFrames_splited_by_second.append(test)\n",
        "  \n",
        "  new_dataFrames_splited_by_second = np.asarray(\n",
        "      new_dataFrames_splited_by_second)\n",
        "  \n",
        "  #print(new_dataFrames_splited_by_second.shape)\n",
        "  #shape = (len(X),final_len,X[0].shape[1])\n",
        "  #X = np.reshape(X,shape)\n",
        "  \n",
        "  return new_dataFrames_splited_by_second\n",
        "\n",
        "\n",
        "############################\n",
        "X_train = completeData(train_dataFrames_splited_per_second,final_len=higher_length)\n",
        "X_test = completeData(test_dataFrames_splited_per_second,final_len=higher_length)\n",
        "print(\"Train:\",X_train.shape,Y_train.shape)\n",
        "print(\"Test:\",X_test.shape,Y_test.shape)\n",
        "#print(X.shape,Y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFYEILFf06pl",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Callback class to print metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "class MetricsPrinter(keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    self.train_accs = []\n",
        "    self.train_precisions = []\n",
        "    self.train_recalls = []\n",
        "    self.train_f1_scores = []\n",
        "    self.test_accs = []\n",
        "    self.test_precisions = []\n",
        "    self.test_recalls = []\n",
        "    self.test_f1_scores = []\n",
        "  \n",
        "  def on_epoch_end(self, epoch, logs={}):  \n",
        "    train_predictions = model.predict(X_train)\n",
        "    y_train_category=[np.argmax(v) for v in Y_train]\n",
        "    y_train_predict_category=[np.argmax(v) for v in train_predictions]\n",
        "    \n",
        "    test_predictions = model.predict(X_test)\n",
        "    y_test_category=[np.argmax(v) for v in Y_test]\n",
        "    y_test_predict_category=[np.argmax(v) for v in test_predictions]\n",
        "    \n",
        "    # ------\n",
        "    \n",
        "    train_acc = accuracy_score(\n",
        "        y_train_category, y_train_predict_category)\n",
        "    \n",
        "    train_precision = precision_score(\n",
        "        y_train_category, y_train_predict_category, average='micro')\n",
        "    \n",
        "    train_recall = recall_score(\n",
        "        y_train_category, y_train_predict_category, average='micro')\n",
        "    \n",
        "    train_f1 = f1_score(\n",
        "        y_train_category, y_train_predict_category, average='micro')\n",
        "    \n",
        "    test_acc = accuracy_score(\n",
        "        y_test_category, y_test_predict_category)\n",
        "    \n",
        "    test_precision = precision_score(\n",
        "        y_test_category, y_test_predict_category, average='micro')\n",
        "    \n",
        "    test_recall = recall_score(\n",
        "        y_test_category, y_test_predict_category, average='micro')\n",
        "    \n",
        "    test_f1 = f1_score(\n",
        "        y_test_category, y_test_predict_category, average='micro')\n",
        "    \n",
        "    # ------\n",
        "    \n",
        "    self.train_accs.append(train_acc)\n",
        "    self.train_precisions.append(train_precision)\n",
        "    self.train_recalls.append(train_recall)\n",
        "    self.train_f1_scores.append(train_f1)\n",
        "\n",
        "    self.test_accs.append(test_acc)\n",
        "    self.test_precisions.append(test_precision)\n",
        "    self.test_recalls.append(test_recall)\n",
        "    self.test_f1_scores.append(test_f1)\n",
        "    \n",
        "    # ------\n",
        "    \n",
        "    print ('train_acc: %.4f\\ttrain_precision: %.4f\\t\\ttrain_recall: %.4f\\ttrain_f1_score: %.4f' \n",
        "           % (train_acc, train_precision, train_recall, train_f1))\n",
        "    \n",
        "    print ('test_acc: %.4f\\ttest_precision: %.4f\\t\\ttest_recall: %.4f\\ttest_f1_score: %.4f' \n",
        "           % (test_acc, test_precision, test_recall, test_f1))\n",
        "    \n",
        "    print ('----------------------------------------------------------')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGJa_MMsbJS1",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Create the model\n",
        "keras.backend.clear_session()\n",
        "input_shape = X_train.shape[1:]\n",
        "print(input_shape)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "activation_Dense='softmax' \n",
        "units = 200\n",
        "\n",
        "#LSTM MODEL\n",
        "\n",
        "model.add(Bidirectional(CuDNNLSTM(units=units,\n",
        "                                  return_sequences=True,\n",
        "                                  input_shape=input_shape)))\n",
        "\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "model.add(Bidirectional(CuDNNLSTM(units=units,\n",
        "                                  return_sequences=True)))\n",
        "\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "model.add(Bidirectional(CuDNNLSTM(units=units,\n",
        "                                  return_sequences=True)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(12,activation=activation_Dense))\n",
        "\n",
        "\n",
        "adam = optimizers.Adam(lr=0.001, \n",
        "                       beta_1=0.9, \n",
        "                       beta_2=0.999, \n",
        "                       epsilon=None, \n",
        "                       decay=0.0, \n",
        "                       amsgrad=False)\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = adam)\n",
        "\n",
        "metricsPrinter = MetricsPrinter()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwnSh1SII73x",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Train the model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "number_of_epochs = 12 #35\n",
        "\n",
        "model.fit(\n",
        "  X_train,\n",
        "  Y_train,\n",
        "  epochs=number_of_epochs,\n",
        "  batch_size=32, \n",
        "  verbose=1, \n",
        "  shuffle=True,\n",
        "  callbacks=[metricsPrinter]\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(10,5), dpi=100)\n",
        "plt.grid(True, axis='y', linestyle='--', linewidth=0.5)\n",
        "\n",
        "\n",
        "plt.plot(metricsPrinter.train_f1_scores, 'bo-', linewidth=3)\n",
        "plt.plot(metricsPrinter.test_f1_scores, 'ro-', linewidth=3)\n",
        "plt.ylabel('Percentage')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train F1-score',\n",
        "            'Validation F1-score'])\n",
        "\n",
        "plt.show()\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFaQ2uNmf_AS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "train_predictions = model.predict(X_train)\n",
        "y_train_category=[np.argmax(v) for v in Y_train]\n",
        "y_train_predict_category=[np.argmax(v) for v in train_predictions]\n",
        "    \n",
        "test_predictions = model.predict(X_test)\n",
        "y_test_category=[np.argmax(v) for v in Y_test]\n",
        "y_test_predict_category=[np.argmax(v) for v in test_predictions]\n",
        "\n",
        "\n",
        "labels=[1,2,3,4,5,6,7,8,9,10,11,20]\n",
        "\n",
        "cnf_matrix1 = confusion_matrix(y_train_category, y_train_predict_category)\n",
        "confusion_ma1 = pd.DataFrame(cnf_matrix1, columns=labels, index=labels)\n",
        "\n",
        "cnf_matrix2 = confusion_matrix(y_test_category, y_test_predict_category)\n",
        "confusion_ma2 = pd.DataFrame(cnf_matrix2, columns=labels, index=labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKojwSLeTE39",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Read test set\n",
        "\n",
        "base_test = pd.read_csv(path + 'CompleteDataSet_testing_competition.csv')\n",
        "\n",
        "base_test['TimeStamps'] = pd.to_datetime(base_test['TimeStamps'])\n",
        "base_test = base_test.iloc[1:] \n",
        "real_test_splited_per_second, higher_length_real_test = split_per_second(\n",
        "    base_test,sensors,False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1wmj1MLVAJE",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Generating the final results\n",
        "X_real_test = completeData(X=real_test_splited_per_second,\n",
        "                           final_len=higher_length)\n",
        "\n",
        "print(\"Test size:\",len(X_real_test))\n",
        "real_test_predictions = model.predict(X_real_test)\n",
        "\n",
        "y_predict_real=[np.argmax(t) for t in real_test_predictions]\n",
        "\n",
        "y_predict_real = np.asarray(y_predict_real)+1\n",
        "\n",
        "y_predict_real = [20 if prediction==12 else prediction for prediction \n",
        "                  in y_predict_real]\n",
        "\n",
        "test_real = base_test['TimeStamps'].apply(\n",
        "    lambda x: x.replace(microsecond=0))\n",
        "\n",
        "test_real = test_real.drop_duplicates()\n",
        "\n",
        "test_real = pd.to_datetime(test_real, \n",
        "                           format='%d-%b-%Y %H:%M:%S', \n",
        "                           utc=True)\n",
        "\n",
        "print(test_real.shape[0],len(y_predict_real))\n",
        "\n",
        "d = {'timestamp': test_real, 'target': y_predict_real}\n",
        "final_results = pd.DataFrame(data=d)\n",
        "final_results = final_results[['timestamp','target']]\n",
        "print(final_results.head(100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY0hMHNipxEZ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Submission File\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from google.colab import auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import datetime\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "driveWriter = GoogleDrive(gauth)\n",
        "\n",
        "folder_id = '1-zVMoVGVipYYPDimf1Sw4Gyr8u9oo9_k'\n",
        "file_title = 'submiss_file_' + str(datetime.datetime.now()) + '.csv' \n",
        "\n",
        "submission_file = driveWriter.CreateFile({\n",
        "    'title': file_title,\n",
        "    'parents': [{'kind': 'drive#fileLink', 'id': folder_id}]\n",
        "})\n",
        "\n",
        "submission_file.SetContentString(\n",
        "    final_results.to_csv(\n",
        "        index=False, columns=['timestamp', 'target']\n",
        "    )\n",
        ")\n",
        "\n",
        "submission_file.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}